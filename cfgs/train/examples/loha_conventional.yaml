_base_:
  - cfgs/train/dataset/base_dataset.yaml
  - cfgs/train/train_base.yaml
  - cfgs/train/tuning_base.yaml

plugin_unet:
  loha:
    _target_: lycoris.hcp.LohaBlock.wrap_model
    _partial_: True
    lr: 2e-4
    dim: 8
    alpha: 4
    layers:
      - 're:.*\.attn.?$'
      - 're:.*\.ff$'

plugin_TE:
   loha:
     _target_: lycoris.hcp.LohaBlock.wrap_model
     _partial_: True
     lr: 6e-5
     dim: 4
     alpha: 1
     layers:
       - 're:.*self_attn$'
       - 're:.*mlp$'

unet: null
text_encoder: null
lora_unet: null
lora_text_encoder: null
tokenizer_pt:
  train: null

train:
  train_steps: 5000
  gradient_accumulation_steps: 1
  save_step: 100

  scale_lr: false
  scheduler:
    name: 'constant_with_warmup'
    num_warmup_steps: 500
    num_training_steps: 5000

  loss:
    criterion: # min SNR loss
      _target_: hcpdiff.loss.MinSNRLoss
      gamma: 5.0

model:
  pretrained_model_name_or_path: 'KBlueLeaf/kohaku-v4-rev1.2'
  clip_skip: 1
  tokenizer_repeats: 1
  ema_unet: 0
  ema_text_encoder: 0

data:
  dataset1:
    batch_size: 4
    cache_latents: True

    source:
      data_source1:
        img_root: 'imgs/'
        prompt_template: 'prompt_tuning_template/object.txt'
        caption_file: null # path to image captions (file_words)

        word_names:
          pt1: pt-cat1

    bucket:
      _target_: hcpdiff.data.bucket.RatioBucket.from_files # aspect ratio bucket
      target_area: ${hcp.eval:"512*512"}
      num_bucket: 5